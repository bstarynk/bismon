% file staticanalys-bm.tex, which is \input from bismon-chariot-doc.tex
\section{Static analysis of source code in \emph{Bismon}}
\label{sec:staticanalys}

Static analysis involves a \emph{generated} GCC plugin (whose C++ code
is generated by the \emph{bismon} persistent monitor) which
communicates with the monitor and sends to it some digested form of
the analyzed C or C++ code. Some translation-unit specific processing
can happen in that GCC plugin, but the whole program aspects of the
static code analysis should obviously be done inside the monitor, and
requires -and justifies- its persistence. The complexity and
non-stability of \emph{GCC} internal representations justify some
semi-automatic approach in extracting them (see \S\ref{subsec:analygcc}
below).

The rest of this chapter will be written in the final D1.3\textsuperscript{v2} version.

A significant part of this chapter should be generated (like \emph{GCC
  MELT} generated its documentation, see
\cite{Starynkevitch-GCCMELTweb}) from the persistent state of
\emph{Bismon}. Perhaps this chapter should be put after the ``using
Bismon'' chapter (\S\ref{sec:using}).

\subsection{static analysis of \emph{GCC} code}
\label{subsec:analygcc}

The \emph{GCC} compiler has a complex (and ill-defined,
under-documented and evolving, so unstable) application programming
interface (API) which can be used by plugins. So \emph{Bismon} needs
to analyze the various \emph{GCC} plugin related \emph{header files}
to extract important information about that API, so to be later able
to generate \emph{GCC} plugin code. Such an extraction (inspired by
the approach inside \emph{Clasp}, which does similar things with the
help of \emph{Clang}, see \cite{Schafmeister:2015:CLASP} for details)
needs not to care about the \emph{Gimple} instructions, but only about
the abstract syntax tree in \emph{Tree} and \emph{Generic} forms (see
\cite{gcc-internals} \S11) to retrieve the full description of
\emph{GCC}.

This approach of extracting semi-automatically~\footnote{We are well
  aware that some work still needs to be done manually, in particular
  giving the really useful subpart of the \emph{GCC} API.} the GCC API
(of parsing GCC header files with some simple GCC plugin) is motivated
by past GCC MELT experience (where every feature of the GCC API had to
be \emph{explicitly} and manually described in MELT language; these
descriptions took a lot of time to be written and had to be manually
maintained; however, most of them could in theory be extracted
automatically from GCC headers).

A bootstrapping and incremental approach, in several ``steps'', is
worthwhile (and possible because of persistence): we will first
extract some very simple information from GCC header files, and use
them to improve the next extraction from the same GCC header
files. The \emph{slow} evolution~\footnote{GCC internals are
  \emph{slowly} evolving, because GCC itself is huge: its
  ``navigation'' is as slow as that of a supertanker which needs hours
  to turn and change directions. So for \emph{social} reasons the GCC
  community is changing the API slowly, but there is no promise of
  stability.}  of GCC API is practically relevant (most of the API of
\texttt{gcc-8.3} should stay in the next \texttt{gcc-9.0} version).

Descriptive data related to the API of a particular version of GCC
will thus stay persistently in the \emph{Bismon} monitor, but should
be updated at each release of \emph{GCC}. We care mostly about API
related to optimization passes, \emph{GENERIC}, \emph{Gimple},
\emph{SSA} and \emph{Optimized-Gimple}. We probably don't need to go
at the \emph{RTL} level. The version
\href{https://gcc.gnu.org/gcc-10/}{10 of \textsc{Gcc}} (released in
May 2020) incorporates several
\href{https://gcc.gnu.org/onlinedocs/gcc/Static-Analyzer-Options.html}{static
  analysis options}, that are activated with the \texttt{-fanalyzer}
option to \texttt{g++} or \texttt{gcc}. The version
\href{http://lists.llvm.org/pipermail/llvm-announce/2020-March/000087.html}{10
  of \textsc{Clang}} (released in March 2020) contains an improved
\href{https://clang-analyzer.llvm.org/}{Clang static analyzer} and
\href{https://clang.llvm.org/extra/clang-tidy/}{\texttt{clang-tidy}}
``linter'' like tool, check both coding styles and portability
related conventions. Both compilers are open source and available
\footnote{Both recent \textsc{Gcc} and \textsc{Clang} are buildable as
cross compiler for major 32 bits or 64 bits architectures such as
PowerPC, x86, x86-64, or ARM, provided one download their source
code.} on a \textsc{Linux} desktop and both should be of interest for
advanced \emph{IoT} software developers coding in C or in C++ and
capable of using the command line. \textsc{Gcc} analysis features be
configured thru appropriate \texttt{\#pragma}-s, and \textsc{Clang}
analysis features are changeable by conventional comments such as
\texttt{// NOLINT(google-explicit-constructor, google-runtime-int)}.

%Additional content of this \S\ref{subsec:analygcc} will be written
%for the final D1.3\textsuperscript{v2}.


\subsection{static analysis of IoT firmware or application code}
\label{subsec:analysiot}

Once the API of the current version of \emph{GCC} is known to the
persistent monitor, we can generate the C++ code of \emph{GCC} plugins
for cross-compilers used by IoT developers.

A first static analysis, useful to IoT developers, will be related to
whole-program detection of \emph{stack overflow} \index{stack
  overflow} (see also \cite{Payer:2018:MSV}). By the way, such an
analysis is currently not doable by \emph{Frama-C}, because it don't
know the size of each call frame. However, \emph{GCC} is already
computing that size (see the \texttt{-fstack-usage} option which dumps
the size of the call frame of each function, and the
\texttt{-Wframe-larger-than=\emph{bytesize}} option), and we simply
need to extract and keep it. We also need to get a good approximation
of the \emph{control flow graph\index{control flow graph}}. For that
we need to extract basic blocks and just \texttt{GIMPLE\_CALL}
\emph{Gimple} statements (ignoring other kinds of \emph{Gimple}
statements). Of course, indirect calls (thru function pointers, which
are infrequently used in most IoT code) are harder to handle (and
could require interaction with the IoT developer using our monitor, to
annotate them).

A proof-of-concept GCC plugin for GCC 8 (and 9) to take advantage of
existing internal GCC passes to compute some upper approximation of
the call stack size has been developped. That hand-written GCC plugin,
coded in file \texttt{gcc8plugin-demo-chariot-2019Q2.cc} of about a
thousand lines of C++, communicate with the \texttt{bismon} monitor
using some REST HTTP protocol with ad-hoc HTTP \texttt{POST} requests
having a JSON payload, in some \textsc{Chariot} specific JSON
format. The \texttt{bismon} monitor should display that diagnostic in
a Web browser tab. It could also use the \emph{language server
  protocol}~\footnote{See \bmurl{https://langserver.org/} for more.}
which is, in 2019, understood by most free software source code
editors running on Linux, including \texttt{emacs}, or \texttt{vim},
or \texttt{VSCode}. It might even later use the new
\emph{Sarif}\footnote{See
  \bmurl{http://docs.oasis-open.org/sarif/sarif/v2.0/csprd01/sarif-v2.0-csprd01.html}
  for more.}  protocol, designed for communication between static
source code analyser.

Notice that according to
\href{https://www.zdnet.com/article/chrome-70-of-all-security-bugs-are-memory-safety-issues/}{this
  webpage}, nearly 70\% of security bugs affecting the Chrome web
browser (by Google) are related to memory management issues in C++.
It is expected that junior European software developers of
non-critical IoT systems would experiment a similar bug distribution
in their IoT code. A long-term approach could be the costly training
of IoT software engineers to switch to programming languages with
better memory management, such as \href{https://golang.org/}{Go} or
\href{https://www.rust-lang.org/}{Rust}. However, rewriting an entire
IoT code base is too costly, and mixing several programming
languages\footnote{See
\href{https://softwareengineering.stackexchange.com/questions/370135/why-are-multiple-programming-languages-used-in-the-development-of-one-product-or}{this}
for a discussion of why is that interesting. Notice that recent
\href{http://gcc.gnu.org/}{GCC} compilers share some common internal
representations between several language front-ends.} in the same
software product can be worthwhile but requires some rare and
qualified labor. \href{https://gcc.gnu.org/gcc-10}{GCC 10} has a new
\href{https://gcc.gnu.org/onlinedocs/gcc/Static-Analyzer-Options.html}{static
  analysis} framework (with its \texttt{-fanalyzer} compiler option)
and powerful warning options\footnote{It is helpful to pass
\texttt{-Wall -Wextra} to the \texttt{gcc} or \texttt{g++} compiler,
usually thru some
\href{https://en.wikipedia.org/wiki/Build_automation}{build
  automation} tool such as
\href{http://ninja-build.org/}{\texttt{ninja}}}. The
\href{https://clang-analyzer.llvm.org/}{\textsc{Clang} static
  analyzer} could be useful. Some coding rules (such as
\cite{Holzmann:2006:power-of-10} or \index{Misra@\textsc{Misra C}}
\href{https://www.misra.org.uk/}{\textsc{Misra C}}) are available, but
the \href{https://en.wikipedia.org/wiki/Rice's_theorem}{Rice's
  theorem} \index{Rice's theorem} forbids the possibility of a sound
and complete static analyzer: false alarms cannot be avoided, and code \index{code review}
reviews by senior programmers is still necessary.

We probably would also take as an example the analysis of some
\href{http://mqtt.org/}{MQTT library}. The insight is to trust some
existing MQTT implementation~\footnote{Our purpose is not to prove the
  correctness of a given MQTT implementation, which would require a
  formal methods approach Ã  la \textsc{Vessedia}, but to help the
  developer using and trusting it, by checking some specific coding
  rules.}, and to help \emph{junior} developers in using it, by
checking simple coding rules relevant to MQTT.

An interesting \textsc{Chariot}-compatible approach could be to use
\emph{topological data analysis} \index{topological data analysis}
\index{data analysis!topological} (cf
\cite{Chazal:2017:topodatanalys}) techniques, combined with some
machine learning (cf \cite{flach:2012:machine-learning}) and big data
\index{big data} / data mining \index{data mining} (cf
\cite{wu:2013:big-data-mining, clarke:2016:big-data-risks,
  zuboff:2015:big-other, helbing:2019:big-data-democracy}) approaches,
on some of the several directed graphs (notably the \emph{control flow
graph}, the \emph{call graph}, the \emph{dependency graph} for
example) of the whole analyzed program. Reputable free software
libraries\footnote{See \textsc{TensorFlow} on
\bmurl{https://www.tensorflow.org/}, and \textsc{Gudhi} on
\bmurl{http://gudhi.gforge.inria.fr/}, and many other similar
libraries.} are available on Linux. In principle, such an approach
might be used in \texttt{bismon} for a \emph{semi-automatic} detection
of \index{code smell} \index{smell!code} \emph{code smells}. Sadly,
the lack of allocated human resources, and the strong focus (see
\cite{Heder:2017:TRL}) \index{TRL} on high
TRL\footnote{\emph{Technical Readiness Level} and the
\href{https://en.wikipedia.org/wiki/Technology\_readiness_level}{TRL
  wikipage} for more.} results, forbids even trying such an
interesting approach in \textsc{Chariot}, taking into account that
industrial corporations are not even dreaming of it. However, these
approaches might be tried in some other projects, perhaps
\index{decoder@\textsc{Decoder}}
\href{https://www.decoder-project.eu/}{\textsc{Decoder}}.

\medskip
\subsection{static analysis related to pointers and addresses}
\label{subsec:analysptr}

Pointers \index{pointer} are an important part of the C11 and C++11
language specifications (see \cite{C11:std, CplusPlus11:std})}, but
  are difficult to understand. They need several chapters\footnote{A
    novice programmer should be explained that after \texttt{int
      tab[4]; int* p = \&tab+1;} both \texttt{tab[2]} and
    \index{alias!pointer} \texttt{p[1]} are pointer aliases, but
    \texttt{sizeof(tab)} is not \texttt{sizeof(p-1)} even if
    \texttt{tab == p-1}.}  in C or C++ textbooks such as
  \cite{gusted:t2019:modern, Stroustrup:2014:CplusPlus}. Practically
  \index{null@\texttt{NULL} in C}
  \index{nullptr@\texttt{\textbf{nullptr}} in C++} speaking, a pointer
  is an address, with \texttt{NULL} (in C) or
  \texttt{\textbf{nullptr}} (in C++) having a special and
  distinguished meaning: it is never the same as the result of the
  \index{address} \emph{address-of} operator (unary \texttt{\&} prefix
  operator).

 From the IoT or firmware developer's point of view, pointers -viewed
 as addresses- may behave strangely in practice, and differently from
 the language specifications: in theory, the \texttt{NULL} pointer
 might not sit at address 0. In practice, IoT or firmware developers
 do know that (on most implementations) it \emph{is} at address
 0. Dereferencing the \texttt{NULL} pointer is the prototypical
 example of \emph{undefined behavior}, yet some firmware
 code\footnote{A typical example would be some \textsc{Bios} or
   \textsc{Uefi} firmware or operating system kernel on most PC
   desktop motherboards, see
   \href{https://osdev.org/}{\texttt{osdev.org}} and
   \href{http://tinyvga.com/}{\texttt{tinyvga.com}} for more} may do
 that with good reasons. For example, some
 \href{https://en.wikipedia.org/wiki/AVR_microcontrollers}{\textsc{Avr}
   microcontrollers} \index{avr@\textsc{Avr} microcontroller} (used in
 \index{arduino@\textsc{Arduino} platform}
 \href{https://arduino.cc/}{\textsc{Arduino} platforms} ``the working
 registers are mapped in as the first 32 memory addresses'' (from the
 \href{https://en.wikipedia.org/wiki/AVR_microcontrollers}{AVR
   microcontrollers} wikipage). The
 \href{https://en.wikipedia.org/wiki/MIPS_architecture}{\textsc{Mips}
   architecture} (used by some \textsc{Chariot} partners) has an
 \index{mips@\textsc{Mips} architecture} instruction set without
 proper I/O ports (see
 \href{https://www2.cs.duke.edu/courses/fall13/compsci250/MIPS32\_QRC.pdf}{this}),
 so input/output happens by accessing some dedicated memory locations:
 from the IoT programmer's point of view, physical I/O happens by
 writing into documented memory locations. The opensource
 \href{https://riscv.org/}{\textsc{Risc-V} architecture}
 \index{riscv@\textsc{Risc-V} architecture}, used in IoT (see
 \cite{lee:2020:miot, waterman:2016:riscv-design})) also has
 memory-based input/output, but admit extensions with separate
 input/output ports.

 Most IoT used operating system kernels (see
 \cite{ArpaciDusseau14-Book}, \index{Linux@\textsc{Linux} operating
   system} \index{kernel!operating system} \index{operating system}
 \index{FreeBSD@\textsc{FreeBSD} operating system}
 \index{FreeRTOS@\textsc{FreeRTOS} kernel}
 \href{https://osdev.org}{\texttt{osdev.org}}) such as the
 \textsc{Linux} \href{http://kernel.org/}{kernel} (see also
 \href{https://kernelnewbies.org}{\texttt{kernelnewbies.org}} and
 \href{https://stackoverflow.com/}{\texttt{stackoverflow.com}}),
 \href{https://www.freebsd.org/}{\textsc{FreeBSD}} and
 \href{https://freertos.org/}{\textsc{FreeRTOS}} are managing
 \href{https://en.wikipedia.org/wiki/Process_(computing)}{processes}
 having each their own
 \href{https://en.wikipedia.org/wiki/Virtual_address_space}{virtual
   address space}and provide the
 \href{https://en.wikipedia.org/wiki/Virtual_memory}{virtual memory}
 abstraction, with some
 \href{https://en.wikipedia.org/wiki/File_system}{file systems} to
 application code.
 
\bigskip


%Additional content of this \S\ref{subsec:analysiot} will be written for the final D1.3\textsuperscript{v2}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Local Variables: ;;
%% compile-command: "cd ..; ./build-bismon-doc.sh" ;;
%% End: ;;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
